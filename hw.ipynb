{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import cv2\n",
    "from skimage import feature\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.color import rgb2gray\n",
    "from PIL import Image\n",
    "from skimage.feature import canny\n",
    "from skimage import exposure\n",
    "from skimage.filters import try_all_threshold, sobel\n",
    "from skimage.filters import gaussian\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "from skimage.transform import rescale, resize, downscale_local_mean, estimate_transform\n",
    "\n",
    "from skimage.draw import line\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from skimage.viewer import ImageViewer\n",
    "from skimage import filters, segmentation, io\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import sys, os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert color image to numpy.ndarray and to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './hw_im_1/IMG_20190312_183838.jpg'\n",
    "image = io.imread(file_path)\n",
    "image = resize(image, (image.shape[0] // 4, image.shape[1] // 4),\n",
    "                       anti_aliasing=True)\n",
    "image_bw = rgb2gray(image)\n",
    "plt.imshow(image_bw,cmap=\"gray\")\n",
    "H = image_bw.shape[0]\n",
    "W = image_bw.shape[1]\n",
    "H,W\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_corrected = exposure.adjust_gamma(image_bw, 2)\n",
    "plt.imshow(gamma_corrected,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image = gaussian(gamma_corrected, multichannel=True, sigma=(3,3))\n",
    "plt.imshow(blurred_image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best thresholding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = try_all_threshold(blurred_image, figsize=(10, 8), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the skimage threshold_otsu package\n",
    "from skimage.filters import threshold_otsu\n",
    "# get the global optimal threshold for the leopard image\n",
    "globalthreshold = threshold_otsu(image=image_bw)\n",
    "# apply the threshold to the gray image to obtain a binary image\n",
    "thresholded =image_bw > globalthreshold\n",
    "# finally show the binary image\n",
    "plt.imshow(thresholded,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgedet = canny(thresholded)\n",
    "imgplot = plt.imshow(edgedet, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect edges using Canny algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_edgedet = canny(thresholded, sigma=0)\n",
    "imgplot = plt.imshow(image_edgedet,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n",
    "h, theta, d = hough_line(image_edgedet, theta=tested_angles);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing test image\n",
    "image = binary_dilation(image_edgedet)\n",
    "\n",
    "tested_angles = np.linspace(-np.pi/2, np.pi/2, 360, endpoint=False)\n",
    "h, theta, d = hough_line(image, theta=tested_angles)\n",
    "\n",
    "# Generating figure 1\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=cm.gray)\n",
    "ax[0].set_title('Input image')\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "angle_step = 0.5 * np.diff(theta).mean()\n",
    "d_step = 0.5 * np.diff(d).mean()\n",
    "bounds = [np.rad2deg(theta[0] - angle_step),\n",
    "          np.rad2deg(theta[-1] + angle_step),\n",
    "          d[-1] + d_step, d[0] - d_step]\n",
    "ax[1].imshow(np.log(1 + h), extent=bounds, cmap=cm.gray, aspect=1 / 1.5)\n",
    "ax[1].set_title('Hough transform')\n",
    "ax[1].set_xlabel('Angles (degrees)')\n",
    "ax[1].set_ylabel('Distance (pixels)')\n",
    "ax[1].axis('image')\n",
    "\n",
    "ax[2].imshow(image, cmap=cm.gray)\n",
    "ax[2].set_ylim((image.shape[0], 0))\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title('Detected lines')\n",
    "\n",
    "line_params = []\n",
    "for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
    "    x0, y0 = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "    ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n",
    "    line_params.append((x0,y0,np.tan(angle + np.pi/2)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion from one mathematical notion to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_homogenous(line_params):\n",
    "    homogenous_forms = []\n",
    "    for param in line_params:\n",
    "    #convert to directional form of the linear function\n",
    "    # y = ax + b\n",
    "        x = param[0]\n",
    "        y = param[1]\n",
    "        a = param[2]\n",
    "        b = y - a*x\n",
    "    #convert to cannonical form of the linear function\n",
    "    # Ax + By + C = 0\n",
    "        A = -a\n",
    "        B = 1\n",
    "        C = -b\n",
    "        homogenous_forms.append([A,B,C])\n",
    "        \n",
    "    return homogenous_forms\n",
    "\n",
    "def find_intersections(homogenous_forms):\n",
    "    # print(homogenous_forms)\n",
    "    intersections = set()\n",
    "    for line_1 in homogenous_forms:\n",
    "        for line_2 in homogenous_forms:\n",
    "            #Remove lines that are too close\n",
    "            print(line_2[0])\n",
    "            e = np.cross(line_1,line_2)\n",
    "            #Equation has no solution, cannot divide by zero\n",
    "            if e[2] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                x = e[0]/e[2]\n",
    "                y = e[1]/e[2]\n",
    "                # Intersection points are part of the image\n",
    "                if (0<= x<= W) and (0 <= y <= H):\n",
    "                    intersections.add((x,y))\n",
    "\n",
    "    intersections = list(intersections)\n",
    "    return intersections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "homogenous_forms = convert_to_homogenous(line_params)\n",
    "intersections = find_intersections(homogenous_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['A','B','C','D']\n",
    "for c in intersections:\n",
    "    # plt.plot(c[0], c[1],'ob',color=\"green\")\n",
    "    plt.text(c[0], c[1],f'{alphabet.pop(0)}', color='blue')\n",
    "plt.imshow(image_bw, cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A4 paper card = 210 x 297 mm\n",
    "# 3 pixels per mm\n",
    "w,h = 630, 891\n",
    "\n",
    "A = np.array([w,h])\n",
    "B = np.array([0,h])\n",
    "C = np.array([0,0])\n",
    "D = np.array([w,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = intersections[0]\n",
    "b = intersections[1]\n",
    "c = intersections[2]\n",
    "d = intersections[3]\n",
    "\n",
    "a = np.array([a[0],a[1]])\n",
    "b = np.array([b[0],b[1]])\n",
    "c = np.array([c[0],c[1]])\n",
    "d = np.array([d[0],d[1]])\n",
    "\n",
    "invtf = estimate_transform(\"projective\",src=np.vstack((A,B,C,D)),\n",
    "dst=np.vstack((a,b,c,d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = skimage.transform.warp(image=thresholded,inverse_map=invtf,output_shape=(h,w))\n",
    "plt.imshow(im,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment image and crop images based on bounding box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_vals = list([sum(r) for r in im  ])\n",
    "col_vals = list([sum(c) for c in im.T])\n",
    "\n",
    "plt.plot(col_vals)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(row_vals)\n",
    "plt.show()\n",
    "\n",
    "val = filters.threshold_otsu(im)\n",
    "mask = im < val\n",
    "\n",
    "clean_border = segmentation.clear_border(mask)\n",
    "\n",
    "plt.imshow(clean_border, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#######################\n",
    "# Label image regions #\n",
    "#######################\n",
    "\n",
    "labeled = label(clean_border)\n",
    "image_label_overlay = label2rgb(labeled, image=im)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\n",
    "ax.imshow(image_label_overlay)\n",
    "#plt.show()\n",
    "\n",
    "#########################################\n",
    "# Draw bounding box around each article #\n",
    "#########################################\n",
    "\n",
    "# create array in which to store cropped articles\n",
    "cropped_images = []\n",
    "\n",
    "# define amount of padding to add to cropped image\n",
    "pad = 20\n",
    "\n",
    "for region_index, region in enumerate(regionprops(labeled)):\n",
    "  if region.area < 50:\n",
    "    continue\n",
    "\n",
    "  # draw a rectangle around the segmented articles\n",
    "  # bbox describes: min_row, min_col, max_row, max_col\n",
    "  minr, minc, maxr, maxc = region.bbox\n",
    "  \n",
    "  # use those bounding box coordinates to crop the image\n",
    "  cropped_images.append(im[minr-pad:maxr+pad, minc-pad:maxc+pad])\n",
    "  \n",
    "  rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red', linewidth=2)\n",
    "\n",
    "  ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "###############\n",
    "# Crop images #\n",
    "###############\n",
    "\n",
    "out_dir = \"segmented_articles/\"\n",
    "if not os.path.exists(out_dir):\n",
    "  os.makedirs(out_dir)\n",
    "\n",
    "# can crop using: cropped = image_array[x1:x2,y1:y2]\n",
    "for c, cropped_image in enumerate(cropped_images):\n",
    "  new_image = skimage.transform.resize(cropped_image, (28,28))\n",
    "  io.imsave( out_dir + str(c) + \".jpeg\", new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_check = []\n",
    "for i in cropped_images:\n",
    "    images_to_check.append(skimage.transform.resize(i, (28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models based on mnist-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "batch_size = 128\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in images_to_check:\n",
    "    x = tf.convert_to_tensor(i)\n",
    "    print(x.shape)\n",
    "    x = tf.reshape(x,(-1, 28, 28, 1))\n",
    "    plt.imshow(i,cmap='gray')\n",
    "\n",
    "    # xtrain = tf.expand_dims(i, axis=-1)\n",
    "    predictions = model.predict(x)\n",
    "    print(f'class: {predictions.argmax()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=3\n",
    "cols = 2\n",
    "img_count = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(14,14))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):        \n",
    "        if img_count < len(images):\n",
    "            x = tf.convert_to_tensor(images_to_check[img_count])\n",
    "            x = tf.reshape(x,(-1, 28, 28, 1))\n",
    "            predictions = model.predict(x)\n",
    "\n",
    "            axes[i, j].imshow(images_to_check[img_count], cmap='gray')\n",
    "            axes[i, j].set_title(f'prediction: {predictions.argmax()}')\n",
    "\n",
    "            img_count+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a893c27a9ac7da36731c1c3b7293e4e0216dbef33ec69ad58d63fa40ce12a09d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('compvis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
